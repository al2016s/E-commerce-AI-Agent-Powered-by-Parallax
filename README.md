# E-commerce-AI-Agent-Powered-by-Parallax
ä¸€ä¸ªåŸºäº Parallax æ¡†æ¶æ„å»ºçš„ã€æ³¨é‡éšç§ä¿æŠ¤çš„æœ¬åœ°åŒ–è·¨å¢ƒç”µå•† AI å®¢æœæ™ºèƒ½ä½“ã€‚
# ğŸ›ï¸ Secure Cross-Border E-commerce AI Agent (Powered by Gradient Parallax)
# åŸºäº Parallax çš„è·¨å¢ƒç”µå•†éšç§ä¿æŠ¤ AI å®¢æœ

> ğŸŒ **A privacy-first, locally deployed AI customer service agent for high-ticket furniture e-commerce.**
>
> ğŸ”’ **ä¸€ä¸ªåŸºäº Parallax æ¡†æ¶æ„å»ºçš„ã€æ³¨é‡éšç§ä¿æŠ¤çš„æœ¬åœ°åŒ–è·¨å¢ƒç”µå•† AI å®¢æœæ™ºèƒ½ä½“ã€‚**

<img width="3840" height="2160" alt="Untitled_01" src="https://github.com/user-attachments/assets/18c67422-6de5-40b1-ac15-854f68aacced" />

## ğŸ“– Introduction (é¡¹ç›®ç®€ä»‹)

This project demonstrates a **fully local AI customer support solution** designed for cross-border e-commerce businesses. It leverages **Gradient Network's Parallax framework** to run the Qwen3 model effectively on consumer hardware (Mac mini).

æœ¬é¡¹ç›®å±•ç¤ºäº†ä¸€ä¸ªä¸“ä¸ºè·¨å¢ƒç”µå•†ä¸šåŠ¡è®¾è®¡çš„**å…¨æœ¬åœ°åŒ– AI å®¢æœè§£å†³æ–¹æ¡ˆ**ã€‚åˆ©ç”¨ **Gradient Network çš„ Parallax æ¡†æ¶**ï¼Œæˆ‘åœ¨æ¶ˆè´¹çº§ç¡¬ä»¶ï¼ˆMac miniï¼‰ä¸ŠæˆåŠŸè¿è¡Œäº† Qwen3 æ¨¡å‹ã€‚

### The Core Problem (ç—›ç‚¹)
In the high-ticket furniture market, **data privacy is paramount**.
* **Supply Chain Risks**: Relying on public cloud LLMs risks leaking product selection logic. In China, supply chains (e.g., 1688) are transparent, and data leaks can lead to immediate copycats.
* **Cost Control**: Traditional AI APIs can be costly for high-volume inquiries.

**è·¨å¢ƒç”µå•†ï¼ˆç‰¹åˆ«æ˜¯é«˜å®¢å•ä»·å®¶å…·ï¼‰æœ€æ€•ä»€ä¹ˆï¼Ÿ**
* **æ€•æ³„éœ²**ï¼šäº‘ç«¯å¤§æ¨¡å‹å¯èƒ½å­˜åœ¨æ•°æ®éšç§é£é™©ã€‚å›½å†…ä¾›åº”é“¾é€æ˜ï¼Œä¸€æ—¦é€‰å“è¢«åŒè¡Œé€šè¿‡æ•°æ®åˆ†ææ‘¸é€ï¼Œå¾ˆå®¹æ˜“è¢«è·Ÿå–å¤åˆ¶ã€‚
* **æˆæœ¬é«˜**ï¼šå•†ä¸š API è°ƒç”¨æˆæœ¬éšç€å’¨è¯¢é‡å¢åŠ è€Œå¢åŠ ã€‚

**Solution**: By deploying locally with Parallax, we ensure data stays local to protect business privacy, while automatically handling 80% of pre-sales and after-sales inquiries to reduce customer service workload.
**è§£å†³æ–¹æ¡ˆ**ï¼šé€šè¿‡ Parallax å®ç°æœ¬åœ°éƒ¨ç½²ï¼Œç¡®ä¿æ•°æ®ä¸å‡ºæœ¬åœ°ï¼Œä¿æŠ¤ä¸šåŠ¡éšç§ï¼Œæ‹¦æˆª 80% çš„å”®å‰å”®åå’¨è¯¢ï¼Œé™ä½å®¢æœå·¥ä½œå‹åŠ›ã€‚

---

## ğŸš€ Tech Stack (æŠ€æœ¯æ ˆ)

* **Inference Engine (æ¨ç†å¼•æ“)**: [Gradient Parallax](https://github.com/GradientHQ/parallax/)
    * Running **Qwen3-0.6B**. The core distributed AI framework that breaks hardware limits.
    * è¿è¡Œ **Qwen3** æ¨¡å‹ã€‚Gradient çš„å»ä¸­å¿ƒåŒ–åˆ†å¸ƒå¼æ¡†æ¶ï¼Œæ‰“ç ´å•æœºç¡¬ä»¶ç“¶é¢ˆã€‚
* **Embedding Engine (å‘é‡å¼•æ“)**: [Ollama](https://ollama.com/)
    * Running **Qwen3-Embedding-4B** for RAG.
    * è¿è¡Œ **Qwen3-Embedding-4B** æ¨¡å‹ç”¨äºå¤„ç†çŸ¥è¯†åº“çš„å‘é‡åŒ–ã€‚
* **Orchestration (å·¥ä½œæµç¼–æ’)**: [Dify](https://dify.ai/)
    * Workflow & Knowledge Base Management.
    * ç”¨äºé›†æˆæ¨¡å‹ä¸æ­å»ºå®¢æœå·¥ä½œæµã€‚
* **Hardware (ç¡¬ä»¶)**: Mac mini M4 16GB/256GB

---

## ğŸ› ï¸ Architecture & Workflow (æ¶æ„ä¸å·¥ä½œæµ)

1.  **Parallax Node**: Acts as the local LLM provider, utilizing distributed computing to run complex models efficiently.
2.  **Ollama**: Converts the "Furniture Q&A Knowledge Base" into vector embeddings.
3.  **Dify**: Connects the Parallax LLM and Ollama Embeddings to build the chat interface.

**å·¥ä½œæµé€»è¾‘ï¼š**
1.  **Parallax èŠ‚ç‚¹**ï¼šä½œä¸ºæœ¬åœ° LLM æä¾›å•†ï¼Œåˆ©ç”¨åˆ†å¸ƒå¼è®¡ç®—é«˜æ•ˆè¿è¡Œå¤æ‚æ¨¡å‹ã€‚
2.  **Ollama**ï¼šå°†â€œå®¶å…·é—®ç­”çŸ¥è¯†åº“â€è½¬åŒ–ä¸ºå‘é‡æ•°æ®ã€‚
3.  **Dify**ï¼šè¿æ¥ Parallax çš„å¤§æ¨¡å‹èƒ½åŠ›å’Œ Ollama çš„çŸ¥è¯†åº“ï¼Œæ„å»ºæœ€ç»ˆçš„èŠå¤©ç•Œé¢ã€‚

<img width="3838" height="1936" alt="image" src="https://github.com/user-attachments/assets/1f1b23d3-b2ae-44b5-a1ef-b7f9df53288f" />

*(Screenshot: Dify orchestration flow / Dify å·¥ä½œæµç¼–æ’ç•Œé¢)*

## âš¡ï¸ Execution Log & Implementation Process (è¿è¡Œè¿‡ç¨‹è®°å½•)

*This section records the actual steps I took to deploy the system on my Mac mini.*
*æœ¬èŠ‚è®°å½•äº†æˆ‘åœ¨ Mac mini ä¸Šéƒ¨ç½²è¯¥ç³»ç»Ÿçš„å®é™…æ“ä½œæ­¥éª¤ã€‚*

### Step 1: Running Parallax Framework (å¯åŠ¨ Parallax æ¡†æ¶)
I used the VS Code terminal to initialize the Parallax framework and loaded the **Qwen3-0.6B** model as the primary inference engine.
æˆ‘ä½¿ç”¨ VS Code å‘½ä»¤è¡Œå·¥å…·åˆå§‹åŒ–äº† Parallax æ¡†æ¶ï¼ŒåŠ è½½ **Qwen3-0.6B** æ¨¡å‹ä½œä¸ºä¸»è¦æ¨ç†å¼•æ“ã€‚

```bash
# The exact command I used / æˆ‘å®é™…ä½¿ç”¨çš„å‘½ä»¤
parallax run 
parallax join
```

<img width="3840" height="2110" alt="image" src="https://github.com/user-attachments/assets/e78b9190-3fe6-4990-9a4e-4d42e8cb2975" />
(Screenshot: Parallax node running successfully in VS Code / æˆªå›¾ï¼šParallax èŠ‚ç‚¹åœ¨ VS Code ä¸­æˆåŠŸè¿è¡Œ)


<img width="3838" height="2110" alt="image" src="https://github.com/user-attachments/assets/d4f1594e-371d-4517-a25b-5c7e1fc74cbd" />
(Screenshot: Parallax node running successfully in VS Code / æˆªå›¾ï¼šParallax èŠ‚ç‚¹åœ¨ VS Code ä¸­æˆåŠŸè¿è¡Œ)

### Step 2: Preparing Embedding Model (å‡†å¤‡å‘é‡æ¨¡å‹)
To ensure the knowledge base (RAG) works efficiently with Chinese context, I used Ollama to run the qwen3-embedding:4b model.
ä¸ºäº†ç¡®ä¿çŸ¥è¯†åº“ï¼ˆRAGï¼‰åœ¨ä¸­æ–‡è¯­å¢ƒä¸‹é«˜æ•ˆå·¥ä½œï¼Œæˆ‘ä½¿ç”¨ Ollama è¿è¡Œäº† qwen3-embedding:4b æ¨¡å‹ã€‚

```bash
# I pulled the embedding model for vectorization / æˆ‘æ‹‰å–äº†ç”¨äºå‘é‡åŒ–çš„æ¨¡å‹
ollama pull qwen3-embedding:4b
```

<img width="1600" height="1200" alt="image" src="https://github.com/user-attachments/assets/1c7aa80d-2f81-4940-95c1-569dc35e5205" />
( Screenshot of Ollama terminal / Ollama ç»ˆç«¯è¿è¡Œæˆªå›¾)

### Step 3: Dify Integration & Workflow Setup (Dify é›†æˆä¸å·¥ä½œæµæ­å»º)
Finally, I connected the components within Dify. This involved pointing the model provider to my local Parallax endpoint, uploading the business knowledge base file, å’Œ configuring the orchestration workflow.
æœ€åï¼Œæˆ‘åœ¨ Dify ä¸­å®Œæˆäº†ç»„ä»¶è¿æ¥ã€‚è¿™åŒ…æ‹¬å°†æ¨¡å‹ä¾›åº”å•†æŒ‡å‘æˆ‘çš„æœ¬åœ° Parallax ç«¯ç‚¹ï¼Œä¸Šä¼ ä¸šåŠ¡çŸ¥è¯†åº“æ–‡ä»¶ï¼Œå¹¶é…ç½®ç¼–æ’å·¥ä½œæµã€‚

**My Configuration Steps (æˆ‘çš„é…ç½®æ­¥éª¤):**

1.  **Model Provider (æ¨¡å‹ä¾›åº”å•†)**:
    In Dify settings, I added an "OpenAI-API-compatible" provider by configuring the API endpoint to point to the local Parallax node, enabling the connection to the **Qwen3-0.6B** model. I also added the **Ollama embedding** model.
    **æ¨¡å‹ä¾›åº”å•†**ï¼šåœ¨ Dify è®¾ç½®ä¸­ï¼Œæˆ‘æ·»åŠ äº†ä¸€ä¸ª "OpenAI-API-compatible" ä¾›åº”å•†ï¼Œé€šè¿‡è®¾ç½®æ¥å£åœ°å€æŒ‡å‘æœ¬åœ° Parallax ç«¯ç‚¹ï¼Œè¿™æ ·æˆ‘å¯ä»¥è¿æ¥ **Qwen3-0.6B** æ¨¡å‹ã€‚åŒæ—¶æˆ‘æ·»åŠ äº† **Ollama** çš„ embedding æ¨¡å‹ã€‚
<img width="3838" height="1926" alt="image" src="https://github.com/user-attachments/assets/14b225e7-b5c9-488d-b5aa-b2554d7d70ae" />
<img width="1758" height="870" alt="image" src="https://github.com/user-attachments/assets/949341be-8a0f-42c9-b125-eded45fd79b2" />


3.  **Knowledge Base (çŸ¥è¯†åº“)**:
    I uploaded the `æ¾³æ´²å®¢æœæŒ‡å¼•.md` (Australian Customer Service Guide) file. This document covers comprehensive business data regarding pre-sales, mid-sales, å’Œ after-sales, including materials and shipping policies.
    **çŸ¥è¯†åº“**ï¼šæˆ‘ä¸Šä¼ äº†è¦†ç›–å”®å‰ã€å”®ä¸­ã€å”®åï¼Œæœ‰å…³æè´¨å’Œå‘è´§æ”¿ç­–ç­‰ä¸šåŠ¡æ•°æ®çš„ `æ¾³æ´²å®¢æœæŒ‡å¼•.md` æ–‡ä»¶ã€‚
<img width="3840" height="1932" alt="image" src="https://github.com/user-attachments/assets/99e09ff1-40e9-4cb6-8aa3-c12243782f27" />

4.  **Prompt Engineering (æç¤ºè¯å·¥ç¨‹)**:
    I designed a system prompt to ensure the AI acts as a professional, privacy-conscious customer service representative.
    **æç¤ºè¯å·¥ç¨‹**ï¼šæˆ‘è®¾è®¡äº†ç³»ç»Ÿæç¤ºè¯ï¼Œç¡®ä¿ AI æ‰®æ¼”ä¸€ä¸ªä¸“ä¸šä¸”æ³¨é‡éšç§çš„å®¢æœä»£è¡¨ã€‚
<img width="878" height="966" alt="image" src="https://github.com/user-attachments/assets/b0767c32-a14c-4cf2-b8ff-30f242fe3a99" />


6.  **Workflow Orchestration (å·¥ä½œæµç¼–æ’)**:
    I set up the overall workflow in several steps: User queries are first processed through **Knowledge Base Retrieval**. Then, the **Qwen3-0.6B** model generates a response using the retrieved data. Finally, I added a **Code Node** to hide the "thinking process" (Chain of Thought) to improve the frontend user experience.
    **å·¥ä½œæµç¼–æ’**ï¼šæˆ‘è®¾ç½®äº†æ•´ä½“çš„å·¥ä½œæµï¼Œåˆ†ä¸ºå‡ æ­¥ï¼šå®¢æˆ·çš„é—®é¢˜å…ˆé€šè¿‡**çŸ¥è¯†åº“æ£€ç´¢**ï¼Œä½¿ç”¨ **Qwen3-0.6B** æ¨¡å‹ç»“åˆæ£€ç´¢åˆ°çš„æ•°æ®è¿›è¡Œå›ç­”ã€‚æœ€åï¼Œä¸ºäº†å‰ç«¯ä½“éªŒï¼Œæˆ‘æ·»åŠ äº†ä¸€ä¸ª**ä»£ç èŠ‚ç‚¹**æ¥éšè—æ¨¡å‹çš„æ€è€ƒè¿‡ç¨‹ã€‚

<img width="3840" height="1932" alt="image" src="https://github.com/user-attachments/assets/2a9dcc95-6e4b-48ce-bcfe-1ebe5c1cc037" />

*(Screenshot: Dify model provider configuration connecting to Parallax / æˆªå›¾ï¼šDify è¿æ¥åˆ° Parallax çš„æ¨¡å‹é…ç½®ç•Œé¢)*

---

## ğŸ“Š Demo & Results (æ¼”ç¤ºä¸æ•ˆæœ)

Here is the actual performance of the agent running on my Mac mini. It successfully retrieved business knowledge from the local knowledge base without leaking data to the cloud.
è¿™æ˜¯æ™ºèƒ½ä½“åœ¨æˆ‘çš„ Mac mini ä¸Šè¿è¡Œçš„å®é™…è¡¨ç°ã€‚å®ƒæˆåŠŸä»æœ¬åœ°çŸ¥è¯†åº“ä¸­æ£€ç´¢äº†ä¸šåŠ¡çŸ¥è¯†ï¼Œä¸”æ²¡æœ‰å°†æ•°æ®æ³„éœ²åˆ°äº‘ç«¯ã€‚

<img width="3838" height="1932" alt="image" src="https://github.com/user-attachments/assets/e2169dc7-f21a-4bbe-9cff-038402f80f41" />

*(Screenshot: Final conversation interface showing the agent solving a problem / æˆªå›¾ï¼šæœ€ç»ˆå¯¹è¯ç•Œé¢ï¼Œå±•ç¤ºæ™ºèƒ½ä½“è§£å†³é—®é¢˜)*

---

## ğŸ† Gradient Network Campaign Submission

This repository is a submission for the **Gradient Network Campaign**.

It documents my journey of building an **Intelligent AI Customer Service Agent** using **Parallax**. By running the **Qwen3-0.6B** model on a distributed edge network (my local device), I successfully **reduced customer service burden while ensuring business privacy**ã€‚

æœ¬ä»“åº“æ˜¯ **Gradient Network Campaign** çš„å‚èµ›ä½œå“ã€‚
å®ƒè®°å½•äº†æˆ‘ä½¿ç”¨ **Parallax** æ„å»º**æ™ºèƒ½ AI å®¢æœåº”ç”¨**çš„è¿‡ç¨‹ã€‚é€šè¿‡åœ¨åˆ†å¸ƒå¼è¾¹ç¼˜ç½‘ç»œï¼ˆæˆ‘çš„æœ¬åœ°è®¾å¤‡ï¼‰ä¸Šè¿è¡Œ **Qwen3-0.6B** æ¨¡å‹ï¼Œæˆ‘æˆåŠŸ**é™ä½äº†å®¢æœå·¥ä½œè´Ÿæ‹…ï¼ŒåŒæ—¶ç¡®ä¿äº†ä¸šåŠ¡éšç§**ã€‚

## ğŸ‘¤ Author (ä½œè€…)

**Echo**
* ğŸ›ï¸ Cross-border E-commerce Practitioner / è·¨å¢ƒç”µå•†ä»ä¸šè€…
* ğŸ¤– AI & Web3 Enthusiast / AI ä¸ Web3 çˆ±å¥½è€…
